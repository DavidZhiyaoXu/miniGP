2025-03-18 15:02:38,364 - INFO - Unable to initialize backend 'cuda': 
2025-03-18 15:02:38,364 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
2025-03-18 15:02:38,365 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/Users/zhiyaoxu/opt/anaconda3/lib/libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/zhiyaoxu/opt/anaconda3/lib/libtpu.so' (no such file), '/Users/zhiyaoxu/opt/anaconda3/bin/../lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file), '/usr/local/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache)
2025-03-18 15:02:38,824 - INFO - FUNCTION FITTING LOSS
2025-03-18 15:02:39,197 - INFO - [f-fit] Step 0: Loss 88442912.000000
2025-03-18 15:02:39,511 - INFO - [f-fit] Step 500: Loss 44.948402
2025-03-18 15:02:39,561 - INFO - [f-fit] Step 1000: Loss 11.018132
2025-03-18 15:02:39,608 - INFO - [f-fit] Step 1500: Loss 7.871768
2025-03-18 15:02:39,655 - INFO - [f-fit] Step 2000: Loss 5.628497
2025-03-18 15:02:39,702 - INFO - [f-fit] Step 2500: Loss 3.803981
2025-03-18 15:02:39,746 - INFO - [f-fit] Step 3000: Loss 2.519323
2025-03-18 15:02:39,791 - INFO - [f-fit] Step 3500: Loss 1.739671
2025-03-18 15:02:39,836 - INFO - [f-fit] Step 4000: Loss 1.382300
2025-03-18 15:02:39,884 - INFO - [f-fit] Step 4500: Loss 1.252507
2025-03-18 15:02:39,930 - INFO - [f-fit] Step 5000: Loss 1.140832
2025-03-18 15:02:39,975 - INFO - [f-fit] Step 5500: Loss 0.929469
2025-03-18 15:02:40,020 - INFO - [f-fit] Step 6000: Loss 0.670256
2025-03-18 15:02:40,065 - INFO - [f-fit] Step 6500: Loss 0.477418
2025-03-18 15:02:40,112 - INFO - [f-fit] Step 7000: Loss 0.339651
2025-03-18 15:02:40,156 - INFO - [f-fit] Step 7500: Loss 0.240296
2025-03-18 15:02:40,202 - INFO - [f-fit] Step 8000: Loss 0.170932
2025-03-18 15:02:40,249 - INFO - [f-fit] Step 8500: Loss 0.123239
2025-03-18 15:02:40,296 - INFO - [f-fit] Step 9000: Loss 0.091409
2025-03-18 15:02:40,344 - INFO - [f-fit] Step 9500: Loss 0.070313
2025-03-18 15:02:40,391 - INFO - [f-fit] Step 10000: Loss 0.055209
2025-03-18 15:02:40,438 - INFO - [f-fit] Step 10500: Loss 0.043179
2025-03-18 15:02:40,485 - INFO - [f-fit] Step 11000: Loss 0.031807
2025-03-18 15:02:40,532 - INFO - [f-fit] Step 11500: Loss 0.022370
2025-03-18 15:02:40,579 - INFO - [f-fit] Step 12000: Loss 0.015221
2025-03-18 15:02:40,626 - INFO - [f-fit] Step 12500: Loss 0.010260
2025-03-18 15:02:40,673 - INFO - [f-fit] Step 13000: Loss 0.006963
2025-03-18 15:02:40,719 - INFO - [f-fit] Step 13500: Loss 0.004719
2025-03-18 15:02:41,206 - INFO - GRADIENT FITTING LOSS
2025-03-18 15:02:41,547 - INFO - [grad-fit] Step 0: Loss 63733468.000000
2025-03-18 15:02:41,864 - INFO - [grad-fit] Step 500: Loss 205.906433
2025-03-18 15:02:41,909 - INFO - [grad-fit] Step 1000: Loss 24.247921
2025-03-18 15:02:41,955 - INFO - [grad-fit] Step 1500: Loss 6.044960
2025-03-18 15:02:42,002 - INFO - [grad-fit] Step 2000: Loss 2.834720
2025-03-18 15:02:42,049 - INFO - [grad-fit] Step 2500: Loss 1.849715
2025-03-18 15:02:42,093 - INFO - [grad-fit] Step 3000: Loss 1.502967
2025-03-18 15:02:42,138 - INFO - [grad-fit] Step 3500: Loss 1.405351
2025-03-18 15:02:42,186 - INFO - [grad-fit] Step 4000: Loss 1.387896
2025-03-18 15:02:42,234 - INFO - [grad-fit] Step 4500: Loss 1.386182
2025-03-18 15:02:42,282 - INFO - [grad-fit] Step 5000: Loss 1.386110
2025-03-18 15:02:42,331 - INFO - [grad-fit] Step 5500: Loss 1.386095
2025-03-18 15:02:42,380 - INFO - [grad-fit] Step 6000: Loss 1.386089
2025-03-18 15:02:42,428 - INFO - [grad-fit] Step 6500: Loss 1.386089
2025-03-18 15:02:42,477 - INFO - [grad-fit] Step 7000: Loss 1.386089
2025-03-18 15:02:42,525 - INFO - [grad-fit] Step 7500: Loss 1.386089
2025-03-18 15:02:42,574 - INFO - [grad-fit] Step 8000: Loss 1.386089
2025-03-18 15:02:42,622 - INFO - [grad-fit] Step 8500: Loss 1.386089
2025-03-18 15:02:42,670 - INFO - [grad-fit] Step 9000: Loss 1.386089
2025-03-18 15:02:42,717 - INFO - [grad-fit] Step 9500: Loss 1.386089
2025-03-18 15:02:42,761 - INFO - [grad-fit] Step 10000: Loss 1.386089
2025-03-18 15:02:42,805 - INFO - [grad-fit] Step 10500: Loss 1.386089
2025-03-18 15:02:42,850 - INFO - [grad-fit] Step 11000: Loss 1.386089
2025-03-18 15:02:42,894 - INFO - [grad-fit] Step 11500: Loss 1.386089
2025-03-18 15:02:42,939 - INFO - [grad-fit] Step 12000: Loss 1.386089
2025-03-18 15:02:42,983 - INFO - [grad-fit] Step 12500: Loss 1.386089
2025-03-18 15:02:43,028 - INFO - [grad-fit] Step 13000: Loss 1.386089
2025-03-18 15:02:43,072 - INFO - [grad-fit] Step 13500: Loss 1.386089
